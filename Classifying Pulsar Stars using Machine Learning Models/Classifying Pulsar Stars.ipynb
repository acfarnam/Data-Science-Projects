{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Pulsar Stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey. \n",
    "\n",
    "Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. \n",
    "\n",
    "As pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars \n",
    "rotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes. \n",
    "\n",
    "Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation. Thus a potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find. \n",
    "\n",
    "Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, which treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation. \n",
    "\n",
    "The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency (see [3] for more details). The remaining four variables are similarly obtained from the DM-SNR curve (again see [3] for more details). These are summarised below: \n",
    "\n",
    "1. Mean of the integrated profile. \n",
    "2. Standard deviation of the integrated profile. \n",
    "3. Excess kurtosis of the integrated profile. \n",
    "4. Skewness of the integrated profile. \n",
    "5. Mean of the DM-SNR curve. \n",
    "6. Standard deviation of the DM-SNR curve. \n",
    "7. Excess kurtosis of the DM-SNR curve. \n",
    "8. Skewness of the DM-SNR curve. \n",
    "9. Class \n",
    "\n",
    "HTRU 2 Summary \n",
    "17,898 total examples. \n",
    "1,639 positive examples. \n",
    "16,259 negative examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pulsars = pd.read_csv(\"/Users/cain/Documents/Projects/Data Sets/pulsar_stars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17898 entries, 0 to 17897\n",
      "Data columns (total 9 columns):\n",
      " Mean of the integrated profile                  17898 non-null float64\n",
      " Standard deviation of the integrated profile    17898 non-null float64\n",
      " Excess kurtosis of the integrated profile       17898 non-null float64\n",
      " Skewness of the integrated profile              17898 non-null float64\n",
      " Mean of the DM-SNR curve                        17898 non-null float64\n",
      " Standard deviation of the DM-SNR curve          17898 non-null float64\n",
      " Excess kurtosis of the DM-SNR curve             17898 non-null float64\n",
      " Skewness of the DM-SNR curve                    17898 non-null float64\n",
      "target_class                                     17898 non-null int64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "pulsars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       140.562500   \n",
       "1                       102.507812   \n",
       "2                       103.015625   \n",
       "3                       136.750000   \n",
       "4                        88.726562   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      55.683782   \n",
       "1                                      58.882430   \n",
       "2                                      39.341649   \n",
       "3                                      57.178449   \n",
       "4                                      40.672225   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                   -0.234571   \n",
       "1                                    0.465318   \n",
       "2                                    0.323328   \n",
       "3                                   -0.068415   \n",
       "4                                    0.600866   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.699648                   3.199833   \n",
       "1                            -0.515088                   1.677258   \n",
       "2                             1.051164                   3.121237   \n",
       "3                            -0.636238                   3.642977   \n",
       "4                             1.123492                   1.178930   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                19.110426   \n",
       "1                                14.860146   \n",
       "2                                21.744669   \n",
       "3                                20.959280   \n",
       "4                                11.468720   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.975532                      74.242225   \n",
       "1                             10.576487                     127.393580   \n",
       "2                              7.735822                      63.171909   \n",
       "3                              6.896499                      53.593661   \n",
       "4                             14.269573                     252.567306   \n",
       "\n",
       "   target_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulsars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.079968</td>\n",
       "      <td>46.549532</td>\n",
       "      <td>0.477857</td>\n",
       "      <td>1.770279</td>\n",
       "      <td>12.614400</td>\n",
       "      <td>26.326515</td>\n",
       "      <td>8.303556</td>\n",
       "      <td>104.857709</td>\n",
       "      <td>0.091574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.652935</td>\n",
       "      <td>6.843189</td>\n",
       "      <td>1.064040</td>\n",
       "      <td>6.167913</td>\n",
       "      <td>29.472897</td>\n",
       "      <td>19.470572</td>\n",
       "      <td>4.506092</td>\n",
       "      <td>106.514540</td>\n",
       "      <td>0.288432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.812500</td>\n",
       "      <td>24.772042</td>\n",
       "      <td>-1.876011</td>\n",
       "      <td>-1.791886</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>7.370432</td>\n",
       "      <td>-3.139270</td>\n",
       "      <td>-1.976976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.929688</td>\n",
       "      <td>42.376018</td>\n",
       "      <td>0.027098</td>\n",
       "      <td>-0.188572</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>14.437332</td>\n",
       "      <td>5.781506</td>\n",
       "      <td>34.960504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115.078125</td>\n",
       "      <td>46.947479</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>0.198710</td>\n",
       "      <td>2.801839</td>\n",
       "      <td>18.461316</td>\n",
       "      <td>8.433515</td>\n",
       "      <td>83.064556</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.085938</td>\n",
       "      <td>51.023202</td>\n",
       "      <td>0.473325</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>5.464256</td>\n",
       "      <td>28.428104</td>\n",
       "      <td>10.702959</td>\n",
       "      <td>139.309331</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>192.617188</td>\n",
       "      <td>98.778911</td>\n",
       "      <td>8.069522</td>\n",
       "      <td>68.101622</td>\n",
       "      <td>223.392140</td>\n",
       "      <td>110.642211</td>\n",
       "      <td>34.539844</td>\n",
       "      <td>1191.000837</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "count                     17898.000000   \n",
       "mean                        111.079968   \n",
       "std                          25.652935   \n",
       "min                           5.812500   \n",
       "25%                         100.929688   \n",
       "50%                         115.078125   \n",
       "75%                         127.085938   \n",
       "max                         192.617188   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "count                                   17898.000000   \n",
       "mean                                       46.549532   \n",
       "std                                         6.843189   \n",
       "min                                        24.772042   \n",
       "25%                                        42.376018   \n",
       "50%                                        46.947479   \n",
       "75%                                        51.023202   \n",
       "max                                        98.778911   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "count                                17898.000000   \n",
       "mean                                     0.477857   \n",
       "std                                      1.064040   \n",
       "min                                     -1.876011   \n",
       "25%                                      0.027098   \n",
       "50%                                      0.223240   \n",
       "75%                                      0.473325   \n",
       "max                                      8.069522   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "count                         17898.000000               17898.000000   \n",
       "mean                              1.770279                  12.614400   \n",
       "std                               6.167913                  29.472897   \n",
       "min                              -1.791886                   0.213211   \n",
       "25%                              -0.188572                   1.923077   \n",
       "50%                               0.198710                   2.801839   \n",
       "75%                               0.927783                   5.464256   \n",
       "max                              68.101622                 223.392140   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "count                             17898.000000   \n",
       "mean                                 26.326515   \n",
       "std                                  19.470572   \n",
       "min                                   7.370432   \n",
       "25%                                  14.437332   \n",
       "50%                                  18.461316   \n",
       "75%                                  28.428104   \n",
       "max                                 110.642211   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "count                          17898.000000                   17898.000000   \n",
       "mean                               8.303556                     104.857709   \n",
       "std                                4.506092                     106.514540   \n",
       "min                               -3.139270                      -1.976976   \n",
       "25%                                5.781506                      34.960504   \n",
       "50%                                8.433515                      83.064556   \n",
       "75%                               10.702959                     139.309331   \n",
       "max                               34.539844                    1191.000837   \n",
       "\n",
       "       target_class  \n",
       "count  17898.000000  \n",
       "mean       0.091574  \n",
       "std        0.288432  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulsars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors = pulsars.drop('target_class', axis = 1)\n",
    "target = pulsars['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, \n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = 13)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "models = []\n",
    "acc = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 7.742636826811269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "solver = ['liblinear']\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty, solver=solver)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(classifier, hyperparameters, cv=5, verbose = 1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=7.74, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(penalty = 'l1', C = 7.74, solver = 'liblinear')\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9812290502793296\n",
      "F1 Score:  0.8891820580474934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "LR_acc = accuracy_score(y_test, y_pred)\n",
    "LR_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "models.append('LR')\n",
    "acc.append(LR_acc)\n",
    "f1.append(LR_f1)\n",
    "\n",
    "LR_cm = confusion_matrix(y_test, y_pred, labels = [1,0])\n",
    "\n",
    "print('Accuracy: ', LR_acc)\n",
    "print('F1 Score: ', LR_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 9\n",
      "Best metric: euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_neighbors': [3,5,7,9],\n",
    "    'metric':['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(classifier, hyperparameters, \n",
    "                   verbose = 1, cv = 3)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best K:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best metric:', best_model.best_estimator_.get_params()['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = 9, metric = 'manhattan')\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9818994413407821\n",
      "F1 Score:  0.8935611038107751\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "KNN_acc = accuracy_score(y_test, y_pred)\n",
    "KNN_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "models.append('KNN')\n",
    "acc.append(KNN_acc)\n",
    "f1.append(KNN_f1)\n",
    "\n",
    "KNN_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "print('Accuracy: ', KNN_acc)\n",
    "print('F1 Score: ', KNN_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Disciminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "classifier = LinearDiscriminantAnalysis()\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9776536312849162\n",
      "F1 Score:  0.8626373626373626\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "LDA_acc = accuracy_score(y_test, y_pred)\n",
    "LDA_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "models.append('LDA')\n",
    "acc.append(LDA_acc)\n",
    "f1.append(LDA_f1)\n",
    "\n",
    "LDA_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "print('Accuracy: ', LDA_acc)\n",
    "print('F1 Score: ', LDA_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   43.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "\n",
    "hyperparameters = [{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "clf = GridSearchCV(classifier, hyperparameters, \n",
    "                   verbose = 1, cv = 3)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(C=1000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9803351955307262\n",
      "F1 Score:  0.8845144356955381\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "SVM_acc = accuracy_score(y_test, y_pred)\n",
    "SVM_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "models.append('SVM')\n",
    "acc.append(SVM_acc)\n",
    "f1.append(SVM_f1)\n",
    "\n",
    "SVM_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "print('Accuracy: ', SVM_acc)\n",
    "print('F1 Score: ', SVM_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weight: {0: 1, 1: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state = 0)\n",
    "\n",
    "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "hyperparameters = dict(class_weight=balance)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(classifier, hyperparameters, \n",
    "                   verbose = 1, cv = 3)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best weight:', best_model.best_estimator_.get_params()['class_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(class_weight = 'balanced', random_state = 0)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9678212290502793\n",
      "F1 Score:  0.8208955223880595\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "DT_acc = accuracy_score(y_test, y_pred)\n",
    "DT_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "models.append('DT')\n",
    "acc.append(DT_acc)\n",
    "f1.append(DT_f1)\n",
    "\n",
    "DT_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "print('Accuracy: ', DT_acc)\n",
    "print('F1 Score: ', DT_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.0s finished\n",
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weight: {0: 100, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "hyperparameters = dict(class_weight=balance)\n",
    "\n",
    "\n",
    "clf = GridSearchCV(classifier, hyperparameters, \n",
    "                   verbose = 1, cv = 3)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best weight:', best_model.best_estimator_.get_params()['class_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cain/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                       random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(random_state = 0, class_weight = 'balanced')\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9812290502793296\n",
      "F1 Score:  0.8891820580474934\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "RF_acc = accuracy_score(y_test, y_pred)\n",
    "RF_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "models.append('RF')\n",
    "acc.append(RF_acc)\n",
    "f1.append(RF_f1)\n",
    "\n",
    "RF_cm = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "print('Accuracy: ', RF_acc)\n",
    "print('F1 Score: ', RF_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True, \n",
    "                          file_name='image'):\n",
    "                          \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(file_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Pulsar', 'Noise']\n",
    "\n",
    "plot_confusion_matrix(LR_cm,\n",
    "                      target_names = labels,\n",
    "                      title = 'Logistic Regression',\n",
    "                      cmap = None,\n",
    "                      normalize = False,\n",
    "                      file_name = 'LR_cm.png')\n",
    "                      \n",
    "plot_confusion_matrix(KNN_cm,\n",
    "                      target_names = labels,\n",
    "                      title = 'KNN',\n",
    "                      cmap = None,\n",
    "                      normalize = False,\n",
    "                      file_name = 'KNN_cm.png')                        \n",
    "                      \n",
    "plot_confusion_matrix(LDA_cm,\n",
    "                      target_names = labels,\n",
    "                      title = 'LDA',\n",
    "                      cmap = None,\n",
    "                      normalize = False,\n",
    "                      file_name = 'LDA_cm.png')\n",
    "\n",
    "plot_confusion_matrix(SVM_cm,\n",
    "                      target_names = labels,\n",
    "                      title = 'SVM',\n",
    "                      cmap = None,\n",
    "                      normalize = False,\n",
    "                      file_name = 'SVM_cm.png')    \n",
    "                      \n",
    "plot_confusion_matrix(DT_cm,\n",
    "                      target_names = labels,\n",
    "                      title = 'Decision Tree',\n",
    "                      cmap = None,\n",
    "                      normalize = False,\n",
    "                      file_name = 'DT_cm.png') \n",
    "                      \n",
    "plot_confusion_matrix(RF_cm,\n",
    "                      target_names = labels,\n",
    "                      title = 'Random Forest',\n",
    "                      cmap = None,\n",
    "                      normalize = False,\n",
    "                      file_name = 'RF_cm.png')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
